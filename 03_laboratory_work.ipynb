{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2637847",
   "metadata": {},
   "source": [
    "# Содержание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fd24b5",
   "metadata": {},
   "source": [
    "* [1 Подготовка окружения](#1-Подготовка-окружения)\n",
    "* [2 Mona Liza reconstruction](#2-Mona-Liza-reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83691bbd",
   "metadata": {},
   "source": [
    "# Лабораторная работа №3: Дифференциальный рендеринг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ae3ffe",
   "metadata": {},
   "source": [
    "**Задачи:** \n",
    "\n",
    "1. Воспроизвести эксперимент с Мона Лизой по статье [3D ML. Часть 4: дифференциальный рендеринг](https://habr.com/ru/companies/itmai/articles/520268/).\n",
    "2. Произвести тот же эксперимент на своём лице (подогнать фото по размерам изображения с Мона Лизой и переложить на чёрный фон).\n",
    "\n",
    "**Источники данных:** 1. [Basel face model (2017 version)](https://faces.dmi.unibas.ch/bfm/bfm2017.html)\n",
    "\n",
    "**Описание данных:** изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66765e44",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac33c6b",
   "metadata": {},
   "source": [
    "## 1. Подготовка окружения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c01727",
   "metadata": {},
   "source": [
    "[Installation](https://github.com/BachiLi/redner/wiki/Installation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53e639b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f20445f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture no-display\n",
    "!pip install redner-gpu h5py urllib3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54dec40",
   "metadata": {},
   "source": [
    "Импорт библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc0e73ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyredner'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyredner\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyredner'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyredner\n",
    "import h5py\n",
    "import urllib\n",
    "import time\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib import animation\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2488ab2f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43fbd00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe643ec2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d371b88",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75e284",
   "metadata": {},
   "source": [
    "## 2 Mona Liza reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d45ec8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e6ed65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.device(device)\n",
    "\n",
    "print('Current device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046eeef0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd2a9363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Basel face model\n",
    "with h5py.File(r'./models/model2017-1_bfm_nomouth.h5', 'r') as hf:\n",
    "    \n",
    "    shape_mean = torch.tensor(\n",
    "        hf['shape/model/mean'], \n",
    "        device = device\n",
    "    )\n",
    "    \n",
    "    shape_basis = torch.tensor(\n",
    "        hf['shape/model/pcaBasis'], \n",
    "        device = device\n",
    "    )\n",
    "    \n",
    "    triangle_list = torch.tensor(\n",
    "        hf['shape/representer/cells'], \n",
    "        device = device\n",
    "    )\n",
    "    \n",
    "    color_mean = torch.tensor(\n",
    "        hf['color/model/mean'], \n",
    "        device = device\n",
    "    )\n",
    "    \n",
    "    color_basis = torch.tensor(\n",
    "        hf['color/model/pcaBasis'], \n",
    "        device = device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dbaefb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e036042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "765ff656",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = triangle_list.permute(1, 0).contiguous()\n",
    "\n",
    "def model(cam_pos, \n",
    "          cam_look_at, \n",
    "          shape_coeffs, \n",
    "          color_coeffs, \n",
    "          ambient_color, \n",
    "          dir_light_intensity):\n",
    "    \n",
    "    vertices = (shape_mean + shape_basis @ shape_coeffs).view(-1, 3)\n",
    "    normals = pyrender.compute_vertex_normal(vertices, indices)\n",
    "    colors = (color_mean + color_basis @ color_coeffs).view(-1, 3)\n",
    "    \n",
    "    m = pyrender.Material(use_vertex_color = True)\n",
    "    \n",
    "    obj = pyrender.Object(\n",
    "        vertices=vertices, \n",
    "        indices=indices, \n",
    "        normals=normals, \n",
    "        material=m, \n",
    "        colors=colors\n",
    "    )\n",
    "    \n",
    "    cam = pyrender.Camera(\n",
    "        position=cam_pos,\n",
    "        # Center of the vertices                          \n",
    "        look_at=cam_look_at,\n",
    "        up=torch.tensor([0.0, 1.0, 0.0]),\n",
    "        fov=torch.tensor([45.0]),\n",
    "        resolution=(256, 256)\n",
    "    )\n",
    "    \n",
    "    scene = pyrender.Scene(camera=cam, objects=[obj])\n",
    "    \n",
    "    ambient_light = pyrender.AmbientLight(ambient_color)\n",
    "    \n",
    "    dir_light = pyrender.DirectionalLight(\n",
    "        torch.tensor([0.0, 0.0, -1.0]), \n",
    "        dir_light_intensity\n",
    "    )\n",
    "    \n",
    "    img = pyrender.render_deferred(\n",
    "        scene=scene, \n",
    "        lights=[ambient_light, dir_light]\n",
    "    )\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b7c4d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30d83f2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyrender' has no attribute 'compute_vertex_normal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m cam_pos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.2697\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5.7891\u001b[39m, \u001b[38;5;241m373.9277\u001b[39m])\n\u001b[0;32m      2\u001b[0m cam_look_at \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.2697\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5.7891\u001b[39m, \u001b[38;5;241m54.7918\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcam_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcam_look_at\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m199\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m199\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m imshow(torch\u001b[38;5;241m.\u001b[39mpow(img, \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2.2\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[0;32m     15\u001b[0m face_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/BachiLi/redner/master/tutorials/mona-lisa-cropped-256.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m, in \u001b[0;36mmodel\u001b[1;34m(cam_pos, cam_look_at, shape_coeffs, color_coeffs, ambient_color, dir_light_intensity)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel\u001b[39m(cam_pos, \n\u001b[0;32m      4\u001b[0m           cam_look_at, \n\u001b[0;32m      5\u001b[0m           shape_coeffs, \n\u001b[0;32m      6\u001b[0m           color_coeffs, \n\u001b[0;32m      7\u001b[0m           ambient_color, \n\u001b[0;32m      8\u001b[0m           dir_light_intensity):\n\u001b[0;32m     10\u001b[0m     vertices \u001b[38;5;241m=\u001b[39m (shape_mean \u001b[38;5;241m+\u001b[39m shape_basis \u001b[38;5;241m@\u001b[39m shape_coeffs)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m     normals \u001b[38;5;241m=\u001b[39m \u001b[43mpyrender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_vertex_normal\u001b[49m(vertices, indices)\n\u001b[0;32m     12\u001b[0m     colors \u001b[38;5;241m=\u001b[39m (color_mean \u001b[38;5;241m+\u001b[39m color_basis \u001b[38;5;241m@\u001b[39m color_coeffs)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     14\u001b[0m     m \u001b[38;5;241m=\u001b[39m pyrender\u001b[38;5;241m.\u001b[39mMaterial(use_vertex_color \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pyrender' has no attribute 'compute_vertex_normal'"
     ]
    }
   ],
   "source": [
    "cam_pos = torch.tensor([-0.2697, -5.7891, 373.9277])\n",
    "cam_look_at = torch.tensor([-0.2697, -5.7891, 54.7918])\n",
    "\n",
    "img = model(\n",
    "    cam_pos, \n",
    "    cam_look_at, \n",
    "    torch.zeros(199, device=device),\n",
    "    torch.zeros(199, device=device),\n",
    "    torch.ones(3), \n",
    "    torch.zeros(3)\n",
    ")\n",
    "\n",
    "imshow(torch.pow(img, 1.0/2.2).cpu())\n",
    "\n",
    "face_url = 'https://raw.githubusercontent.com/BachiLi/redner/master/tutorials/mona-lisa-cropped-256.png'\n",
    "\n",
    "urllib.request.urlretrieve(face_url, 'target.png')\n",
    "target = pyrender.imread('target.png').to(pyrender.get_device())\n",
    "\n",
    "imshow(torch.pow(target, 1.0/2.2).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaee19c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29b92ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64c87d49",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddfa9fb",
   "metadata": {},
   "source": [
    "### 2.1 Воксели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b983e731",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0ab0cf3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdbef96",
   "metadata": {},
   "source": [
    "### 2.2 Облако точек"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589c32ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a702fa9a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983cfe94",
   "metadata": {},
   "source": [
    "### 2.3 Функциональная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bf22c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5de1f591",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbc7e29",
   "metadata": {},
   "source": [
    "### 2.4 Карта глубины"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8870bac9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adf23432",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bb6f6b",
   "metadata": {},
   "source": [
    "## 3. Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0f2e12",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 20px; padding: 15px 0;\">\n",
    "    <a href=\"#Содержание\" data-toc-modified-id=\"Содержание\" style=\"text-decoration: none; color: #296eaa; border: 2px dashed #296eaa; opacity: 0.8; border-radius: 3px; padding: 10px 80px;\">\n",
    "        В начало файла ↑\n",
    "    </a>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
